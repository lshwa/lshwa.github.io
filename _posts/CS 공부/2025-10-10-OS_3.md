---
layout: single
title: "Scheduling"
categories: [OS]
tags: [운영체제]
typora-root-url: ../
toc: true
author_profile: false
sidebar:
  nav: "docs"
---

이번 포스트는 OS의 중요 컴포넌트인 **Scheduling**에 대해 다룬다. 



# Scheduling

## Scheduling Introduction

> **Workload Assumptions** (가장 단순하고 이상적인 환경)
>
> 1. 모든 프로세스가 **동일한 실행 시간 (run time)**을 가진다. 
>    - 즉, CPU의 사용 시간이 모두 같다.
> 2. 모든 프로세스가 **동시에 도착** 한다.
> 3. **I/O 작업이 없다.**
>    - 즉 CPU만 사용한다. (순수 CPU-bound workload)
> 4. 각 프로세스의 실행 시간이 미리 **알려져 있다.** (예측 가능성)



**Scheduling Metrics (스케줄링의 평가 기준)** : 

**1. Turnaround Time (반환 시간)**

- **하나의 프로세스가 시스템에 들어온 순간부터 완전히 끝날 때까지 걸린 전체 시간**
  $$
  T_{turnaround} = T_{completion} - T_{arrival}
  $$

- 프로세스가 시스템에 **도착(arrival)** 해서 **완료(completion)**될 때까지 얼마나 오래 걸렸는지를 의미 

  - 프로세스가 기다린 시간 + 실행된 시간이 포함된 것
  - 사용자 입장에서 **작업 요청으로부터 결과를 받기까지의 전체 지연 시간**
  - 반환시간이 작을수록 **시스템의 성능이 좋다고 판단**한다. 



**2. Fairness (공정성)**

- **모든 프로세스가 CPU를 공평하게 사용할 수 있는 정도를 나타내는 지표**
  - 일부 프로세스가 너무 오래 기다리거나, 한 프로세스가 CPU를 독점하지 않도록 하는 것이 목적 



> 두 가지의 평가기준은 **서로 trade-off** 관계 
>
> - 빠른 응답을 원하면 공정성을 포기하고, 모두에게 공평함을 원하면 효율이 떨어진다.



### FIFO (First In, First Out)

![FIFO](/../images/2025-10-10-OS_3/FIFO.png)

정의 : **먼저 들어온 프로세스를 먼저 실행하는 방식**

- 즉, **"도착 순서대로 실행" 하는 가장 단순한 스케줄링 알고리즘**
- 큐(Queue) 자료구조처럼 동작

예시 분석 : 

~~~
(조건)
A, B, C 세 개의 작업이 순서대로 도착
각 job의 실행 시간 = 10초
~~~

| **Job** | **Arrival** | **Completion** | **Turnaround** |
| ------- | ----------- | -------------- | -------------- |
| A       | 0           | 10             | 10             |
| B       | 0           | 20             | 20             |
| C       | 0           | 30             | 30             |

따라서 **Average Turnaround Time**은 
$$
\frac{10 + 20 + 30}{3} = 20\ \text{seconds}
$$


**Convoy Effect (호위 효과)**

- **CPU를 오래 사용하는 하나의 프로세스 때문에, 뒤에 짧은 프로세스들이 모두 기다리는 현상**
  - 즉, **긴 작업 하나로 인해 그 뒤에 있는 짧은 작업들이 호위하듯이 전부 지연**되는 문제 

예시 분석:

~~~
(조건)
A, B, C 세 개의 작업이 순서대로 도착
A는 실행 시간이 100초 / B,C는 10초 
~~~

| **Job** | **Arrival** | **Completion** | **Turnaround (완료–도착)** |
| ------- | ----------- | -------------- | -------------------------- |
| A       | 0           | 100            | 100                        |
| B       | 0           | 110            | 110                        |
| C       | 0           | 120            | 120                        |

따라서 **Average Turnaround Time**은
$$
\frac{100 + 110 + 120}{3} = 110\ \text{seconds}
$$


### SJF (Shortest Job First)

정의 : **실행 시간이 가장 짧은 작업부터 먼저 수행하는 비선점형 (Non-preemptive) 스케줄링**

- CPU **작업의 길이(run time)**를 미리 알고 있다면, 가장 빨리 끝낼 수 있는 것부터 처리하는 방식 

예시 분석:

~~~
(조건)
모든 프로세스가 도착했다고 가정 (arrival time이 같다.)
A의 실행시간은 100초 / B,C는 10초
~~~

- 실행 순서 : **B-> C -> A**

| **Job** | **Completion** | **Turnaround** |
| ------- | -------------- | -------------- |
| B       | 10             | 10             |
| C       | 20             | 20             |
| A       | 120            | 120            |

따라서 **Average Turnaround Time**은
$$
\text{Average turnaround time} = \frac{10 + 20 + 120}{3} = 50\text{ sec}
$$

- 성능 측면에서는 매우 효율적 
- **FIFO랑 비교할 때 평균 반환 시간이 거의 절반 감소**



**SJF with Late Arrivals - 현실적 문제**

위의 가정은 **"모든 작업이 동시에 도착한다"는 비현실적 가정**에 의존함. 

- 예시 분석 (상황)

| **Job** | **Arrival Time** | **Run Time** |
| ------- | ---------------- | ------------ |
| A       | 0                | 100          |
| B       | 10               | 10           |
| C       | 10               | 10           |

- A가 0초에 동작 - CPU는 A를 바로 실행함.
- B,C는 10초에 도착했지만, SJF는 **비선점형**이기 때문에 이미 실행중인 A를 **중간에 끊을수가 없다.**
  - 즉 B,C는 A의 작업이 끝날때까지 계속 기다려야 한다. 

| **ob** | **Completion** | **Arrival** | **Turnaround** |
| ------ | -------------- | ----------- | -------------- |
| A      | 100            | 0           | 100            |
| B      | 110            | 10          | 100            |
| C      | 120            | 10          | 110            |

따라서 **Average Turnaround Time**은
$$
\text{Average turnaround time} = \frac{100 + 100 + 110}{3} = 103.33\text{ sec}
$$


### STCF (Shortest Time-to-Completion First)

정의 : **SJF(Shortest Job First) 방법에 '선점 (preemption)' 개념을 추가한 것**

- 실행 중이더라도 **더 짧은 남은 작업**이 들어오면 CPU를 **즉시 빼앗김**



스케줄링 규칙: 

1. 새 작업이 도착할 때마다, **현재 실행 중인 프로세스**와 **남은 작업**들의 **남은 실행 시간 (remaining time)**을 비교한다.
2. **가장 짧은 남은 실행 시간**을 가진 프로세스가 CPU를 차지한다. 

> 즉 실행 중이던 프로세스라도, 더 짧은 작업이 들어오면 CPU를 **즉시 빼앗긴다. (preemption)**



예시 분석: (위와 동일)

| **Job** | **Arrival Time** | **Run Time** |
| ------- | ---------------- | ------------ |
| A       | 0                | 100          |
| B       | 10               | 10           |
| C       | 10               | 10           |

- A가 0초부터 실행 (A만 있기 때문에 A가 실행중)
- **Time = 10초** : B와 C가 도착
  - A의 남은 시간은 90초 / B,C의 전체 시간 : 10초씩 
  - B, C 가 더 짧기 때문에 **A를 중단하고 B를 실행**
- **Time = 20초** : B 종료 이후 C 실행
- C 종료 이후 다시 A로 복귀하여 남은 90초를 실행 

| **Job** | **Completion** | **Arrival** | **Turnaround** |
| ------- | -------------- | ----------- | -------------- |
| A       | 120            | 0           | 120            |
| B       | 20             | 10          | 10             |
| C       | 30             | 10          | 20             |

따라서 **Average Turnaround Time**은
$$
\text{Average turnaround time} = \frac{120 + 10 + 20}{3} = 50\ \text{sec}
$$

> **선점 기능을 추가함으로써 평균 반환 시간이 절반 수준으로 감소**



>  **New Scheduling metric**
>
> **3. Response Time (응답 시간)**
>
> - 프로세스가 **도착(arrival)** 한 시점부터 **처음으로 CPU를 할당받을 때 (first Scheduled)**까지 걸린 시간 

$$
T_{response} = T_{firstrun} - T_{arrival}
$$



**STCF의 한계**

- 짧은 작업을 우선하기 때문에 **평균 완료 시간**은 매우 좋지만, 한 번 CPU를 잃으면 다시 실행되기까지 오래 기다릴 수도 있어서 **Response Time이 좋지는 않다.**
  - 특히 **긴 작업이 여러 번 선점당할 경우, 사용자는 시스템이 느리다라고 체감**



### RR Scheduling (Round Robin)

![Round Robin](/../images/2025-10-10-OS_3/Round Robin.png)

정의 : **모든 프로세스에 CPU를 공평하게 나누어주는 스케줄링 방식**

- 각 프로세스는 **고정된 시간 (time slice 또는 quantum) 동안만 실행**되고, 시간이 끝나면 다음 프로세스로 **순환(round-robin) 하며 교체**

  > **용어 정리**
  >
  > - **Time Slice (Quantum)** : 한 프로세스가 CPU를 독점할 수 있는 최대 시간
  > - **Time Interrupt** : OS가 CPU를 강제로 빼앗아 다음 프로세스로 넘기는 장치
  > - **Fairness (공정성)** : 모든 프로세스가 일정 주기로 CPU를 사용할 수 있게 보장 

동작 원리:

1. **프로세스들이 'run queue'에 순서대로 대기**
2. CPU는 맨 앞의 프로세스에게 **time slice**만큼 CPU를 할당
3. **시간이 끝나면 Timer Interrupt가 발생**
4. CPU는 현재 프로세스를 **뒤로 보내고**, 다음 프로세스를 실행
5. 이 과정을 **모든 프로세스가 끝날 때까지 반복**



장단점:

- 장 : 응답 시간이 매우 짧아서 사용자 체감이 빠르다 (모든 프로세스가 조금씩 실행되기 때문)
- 단 : context switch 오버헤드가 증가한다. 평균 반환시간은 비효율적이다. 



예시 분석:

| **Job** | **Arrival** | **Run Time** | **첫 실행** | **Response Time** |
| ------- | ----------- | ------------ | ----------- | ----------------- |
| A       | 0           | 5            | 0           | 0                 |
| B       | 0           | 5            | 5           | 5                 |
| C       | 0           | 5            | 10          | 10                |

이 표를 보고 **응답 시간 (Response Time)**을 기준으로 계산하면, **SJF에서는**
$$
T_{avg\_response} = \frac{0 + 5 + 10}{3} = 5\text{ sec}
$$

- RR의 경우 : Time slice = 1초로 가정

| **Job** | **Arrival** | **첫 실행** | **Response Time** |
| ------- | ----------- | ----------- | ----------------- |
| A       | 0           | 0           | 0                 |
| B       | 0           | 1           | 1                 |
| C       | 0           | 2           | 2                 |

따라서 **응답 시간**은
$$
T_{avg\_response} = \frac{0 + 1 + 2}{3} = 1\text{ sec}
$$

> 즉 Time Slice의 길이가 굉장히 중요하다.!!

**Time Slice**

- 프로세스가 CPU를 독점할 수 있는 **최대 시간 단위**
  - **Time Slice 가 짧을 수록** 빠른 응답시간을 가지고 사용자 입장에서 즉각적인 반응을 하지만, context switch가 너무 자주 발생해 오버헤드가 증가한다. 
    - 요약 : **효율성은 낮지만 반응성은 좋다.**
    - 사용자 인터랙티브 프로그램 (UI, 키 입력 등)에 적합 
  - **Time Slice가 길수록** 스위칭 비용이 감소하여 효율이 좋지만, 응답 시간 약화로 사용자가 체감이 느리다. 
    - 요약 : **효율은 좋지만 반응성이 나쁘다.**

> **Trade-off 관계이다.**

---

### Incorporating I/O (입출력 작업 통합)

가정과 다르게 실제 시스템에서는 많은 프로그램이 **I/O (디스크, 네트워크 등)를 자주 수행함.**

예시 상황

- A와 B는 두 프로세스가 각각 **50ms의 CPU 시간**이 필요함.
- 단, A는 **10ms 마다 I/O 요청**을 수행한다.
- B는 I/O없이 CPU만 계속 사용한다. 

가능 시나리오: 

(Poor Use of Resources) 

1. 스케줄러가 A를 먼저 실행
   - A는 10ms 동안 CPU 사용 이후 I/O 요청을 발생
   - A는 **Blocked 상태**로 전환됨.
2. CPU는 놀게 된다. (Idle 상태)
   - A가 I/O를 기다리는 동안 아무 프로세스도 실행되지 않는다. 
3. 이후 B가 실행됨.

> **잘못된 스케줄링**
>
> - CPU가 A의 I/O 중에 놀고 있음. **CPU Utilization이 낮다.**
> - 자원 활용 비효율적



(Overlap Allows Use of Resources)

1. A가 10ms 동안 CPU 사용 이후 I/O 요청 -> Blocked
2. **B를 즉시 실행하여 CPU 낭비 방지**
3. A의 I/O가 끝나면 다시 Ready 상태로 전환되어 다음 번 CPU를 사용

> **올바른 스케줄링**
>
> - **병렬 자원 활용 (CPU + I/O 동시 사용)**
> - **CPU Utilization 이 최대화***



**I/O 관련 스케줄링 메커니즘**

**1. I/O 시작 시**

- 프로세스는 **Blocked 상태**로 전환된다. (I/O 완료까지 대기)
- 스케줄러는 **다른 프로세스**를 즉시 CPU에 배정해야 한다. 



**2. I/O 완료 시**

- **하드웨어 인터럽트 발생**
- OS는 Blocked 상태의 프로세스를 **Ready Queue로 이동**시킨다. 
- 다음 번 스케줄링에서 CPU를 다시 받을 수 있다. 



---

## Scheduling : The Multi-Level Feedback Queue

이어서 넣을 예정..

